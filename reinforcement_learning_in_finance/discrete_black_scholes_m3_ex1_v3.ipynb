{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete-Time Black Scholes\n",
    "Welcome to your 1st assignment in Reinforcement Learning in Finance. This exercise will introduce Black-Scholes model as viewed through the lens of pricing an option as discrete-time replicating portfolio of stock and bond.\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
    "- Do not modify the (# GRADED FUNCTION [function name]) comment in some cells. Your work would not be graded if you change this. Each cell containing that comment should only contain one function.\n",
    "- After coding your function, run the cell right below it to check if your result is correct.\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. You only need to write code between the ### START CODE HERE ### and ### END CODE HERE ### comments. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run Cell\" (denoted by a play symbol) in the upper bar of the notebook. \n",
    "\n",
    "We will often specify \"(≈ X lines of code)\" in the comments to tell you about how much code you need to write. It is just a rough estimate, so don't feel bad if your code is longer or shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import standard_normal, seed\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "#import grading\n",
    "\n",
    "import datetime \n",
    "import time\n",
    "import bspline\n",
    "import bspline.splinelab as splinelab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY FOR GRADING. DO NOT EDIT ###\n",
    "submissions=dict()\n",
    "assignment_key=\"J_L65CoiEeiwfQ53m1Mlug\" \n",
    "all_parts=[\"9jLRK\",\"YoMns\",\"Wc3NN\",\"fcl3r\"]\n",
    "### ONLY FOR GRADING. DO NOT EDIT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSERA_TOKEN = \"V5aiZgrpBRfHfGN9\" # the key provided to the Student under his/her email on submission page\n",
    "COURSERA_EMAIL = \"thomas.han@live.com\" # the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Black-Scholes prices\n",
    "def bs_put(t, S0, K, r, sigma, T):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S0 * norm.cdf(-d1)\n",
    "    return price\n",
    "\n",
    "def bs_call(t, S0, K, r, sigma, T):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = S0 * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)\n",
    "    return price\n",
    "\n",
    "def d1(S0, K, r, sigma, T):\n",
    "    return (np.log(S0/K) + (r + sigma**2 / 2) * T)/(sigma * np.sqrt(T))\n",
    " \n",
    "def d2(S0, K, r, sigma, T):\n",
    "    return (np.log(S0 / K) + (r - sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $N_{MC}$ stock price sample paths with $T$ steps by the classical Black-Sholes formula.\n",
    "\n",
    "$$dS_t=\\mu S_tdt+\\sigma S_tdW_t\\quad\\quad S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n",
    "\n",
    "where $Z$ is a standard normal random variable.\n",
    "\n",
    "MC paths are simulated by GeneratePaths() method of DiscreteBlackScholes class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "\n",
    "Class DiscreteBlackScholes implements the above calculations with class variables to math symbols mapping of:\n",
    "\n",
    "$$\\Delta S_t=S_{t+1} - e^{-r\\Delta t} S_t\\space \\quad t=T-1,...,0$$\n",
    " \n",
    "**Instructions:**\n",
    "Some portions of code in DiscreteBlackScholes have bee taken out. You are to implement the missing portions of code in DiscreteBlackScholes class.\n",
    "\n",
    "$$\\Pi_t=e^{-r\\Delta t}\\left[\\Pi_{t+1}-u_t \\Delta S_t\\right]\\quad t=T-1,...,0$$\n",
    "\n",
    "- implement DiscreteBlackScholes.function_A_vec() method\n",
    "$$A_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\Phi_m\\left(X_t^k\\right)\\left(\\Delta\\hat{S}_t^k\\right)^2}\\quad\\quad$$ \n",
    "\n",
    "- implement DiscreteBlackScholes.function_B_vec() method\n",
    "$$B_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\left[\\hat\\Pi_{t+1}^k\\Delta\\hat{S}_t^k+\\frac{1}{2\\gamma\\lambda}\\Delta S_t^k\\right]}$$\n",
    "- implement DiscreteBlackScholes.gen_paths() method using the following relation:\n",
    "$$S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n",
    "where $Z \\sim N(0,1)$\n",
    "- implement parts of DiscreteBlackScholes.roll_backward()\n",
    "    - DiscreteBlackScholes.bVals corresponds to $B_t$ and is computed as $$B_t = e^{-r\\Delta t}\\left[B_{t+1} + (u_{t+1} - u_t)S_{t+1}\\right]\\quad t=T-1,...,0$$\n",
    "    \n",
    "DiscreteBlackScholes.opt_hedge corresponds to $\\phi_t$ and is computed as \n",
    "     $$\\phi_t=\\mathbf A_t^{-1}\\mathbf B_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteBlackScholes:\n",
    "    \"\"\"\n",
    "    Class implementing discrete Black Scholes\n",
    "    DiscreteBlackScholes is class for pricing and hedging under\n",
    "    the real-world measure for a one-dimensional Black-Scholes setting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 s0,\n",
    "                 strike,\n",
    "                 vol,\n",
    "                 T,\n",
    "                 r,\n",
    "                 mu,\n",
    "                 numSteps,\n",
    "                 numPaths):\n",
    "        \"\"\"\n",
    "        :param s0: initial price of the underlying\n",
    "        :param strike: option strike\n",
    "        :param vol: volatility\n",
    "        :param T: time to maturity, in years\n",
    "        :param r: risk-free rate,\n",
    "        :param mu: real drift, asset drift\n",
    "        :param numSteps: number of time steps\n",
    "        :param numPaths: number of Monte Carlo paths\n",
    "        \"\"\"\n",
    "        self.s0 = s0\n",
    "        self.strike = strike\n",
    "        self.vol = vol\n",
    "        self.T = T\n",
    "        self.r = r\n",
    "        self.mu = mu\n",
    "        self.numSteps = numSteps\n",
    "        self.numPaths = numPaths\n",
    "\n",
    "        self.dt = self.T / self.numSteps  # time step\n",
    "        self.gamma = np.exp(-r * self.dt)  # discount factor for one time step, i.e. gamma in the QLBS paper\n",
    "\n",
    "        self.sVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of stock values\n",
    "\n",
    "        # initialize half of the paths with stock price values ranging from 0.5 to 1.5 of s0\n",
    "        # the other half of the paths start with s0\n",
    "        half_paths = int(numPaths / 2)\n",
    "\n",
    "        if False:\n",
    "            # Grau (2010) \"Applications of Least-Squares Regressions to Pricing and Hedging of Financial Derivatives\"\n",
    "            self.sVals[:, 0] = (np.hstack((np.linspace(0.5 * s0, 1.5 * s0, half_paths),\n",
    "                                           s0 * np.ones(half_paths, 'float')))).T\n",
    "\n",
    "        self.sVals[:, 0] = s0 * np.ones(numPaths, 'float')\n",
    "        self.optionVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of option values\n",
    "        self.intrinsicVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')\n",
    "\n",
    "        self.bVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of cash position values\n",
    "        self.opt_hedge = np.zeros((self.numPaths, self.numSteps + 1),\n",
    "                              'float')  # matrix of optimal hedges calculated from cross-sectional information F_t\n",
    "        self.X = None\n",
    "        self.data = None  # matrix of features, i.e. self.X as sum of basis functions\n",
    "        self.delta_S_hat = None\n",
    "\n",
    "        # coef = 1.0/(2 * gamma * risk_lambda)\n",
    "        # override it by zero to have pure risk hedge\n",
    "        self.coef = 0.\n",
    "\n",
    "    def gen_paths(self):\n",
    "        \"\"\"\n",
    "        A simplest path generator\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        # Spline basis of order p on knots k\n",
    "\n",
    "        ### START CODE HERE ### (≈ 3-4 lines of code)\n",
    "        Z = np.random.normal(0, 1, size=(self.numPaths, self.numSteps + 1))\n",
    "        for t in range(0, self.numSteps):\n",
    "            self.sVals[:, t + 1] = self.sVals[:, t] * np.exp((self.mu - 0.5 * self.vol**2) * self.dt + (self.vol * np.sqrt(self.dt) * Z[:, t + 1]))\n",
    "        \n",
    "        print(\"self.sVals\", self.sVals)\n",
    "        # self.sVals = your code goes here ...\n",
    "        # for-loop or while loop is allowed heres\n",
    "\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # like in QLBS\n",
    "        delta_S = self.sVals[:, 1:] - np.exp(self.r * self.dt) * self.sVals[:, :self.numSteps]\n",
    "        self.delta_S_hat = np.apply_along_axis(lambda x: x - np.mean(x), axis=0, arr=delta_S)\n",
    "\n",
    "        # state variable\n",
    "        # delta_t here is due to their conventions\n",
    "        self.X = - (self.mu - 0.5 * self.vol ** 2) * np.arange(self.numSteps + 1) * self.dt + np.log(self.sVals)\n",
    "\n",
    "        X_min = np.min(np.min(self.X))\n",
    "        X_max = np.max(np.max(self.X))\n",
    "\n",
    "        print('X.shape = ', self.X.shape)\n",
    "        print('X_min, X_max = ', X_min, X_max)\n",
    "\n",
    "        p = 4  # order of spline (as-is; 3 = cubic, 4: B-spline?)\n",
    "        ncolloc = 12\n",
    "        tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n",
    "\n",
    "        # k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n",
    "        # To get meaningful results, one should have ncolloc >= p+1\n",
    "        k = splinelab.aptknt(tau, p)\n",
    "        basis = bspline.Bspline(k, p)\n",
    "\n",
    "        num_basis = ncolloc  # len(k) #\n",
    "        self.data = np.zeros((self.numSteps + 1, self.numPaths, num_basis))\n",
    "\n",
    "        print('num_basis = ', num_basis)\n",
    "        print('dim self.data = ', self.data.shape)\n",
    "\n",
    "        # fill it, expand function in finite dimensional space\n",
    "        # in neural network the basis is the neural network itself\n",
    "        t_0 = time.time()\n",
    "        for ix in np.arange(self.numSteps + 1):\n",
    "            x = self.X[:, ix]\n",
    "            self.data[ix, :, :] = np.array([basis(el) for el in x])\n",
    "        t_end = time.time()\n",
    "        print('\\nTime Cost of basis expansion:', t_end - t_0, 'seconds')\n",
    "\n",
    "    def function_A_vec(self, t, reg_param=1e-3):\n",
    "        \"\"\"\n",
    "        function_A_vec - compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
    "        Eq. (52) in QLBS Q-Learner in the Black-Scholes-Merton article\n",
    "\n",
    "        Arguments:\n",
    "        t - time index, a scalar, an index into time axis of data_mat\n",
    "        reg_param - a scalar, regularization parameter\n",
    "\n",
    "        Return:\n",
    "        - np.array, i.e. matrix A_{nm} of dimension num_basis x num_basis\n",
    "        \"\"\"\n",
    "        X_mat = self.data[t, :, :]\n",
    "        num_basis_funcs = X_mat.shape[1]\n",
    "        this_dS = self.delta_S_hat[:, t]\n",
    "        hat_dS2 = (this_dS ** 2).reshape(-1, 1)\n",
    "        A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n",
    "        return A_mat\n",
    "\n",
    "    def function_B_vec(self, t, Pi_hat):\n",
    "        \"\"\"\n",
    "        function_B_vec - compute vector B_{n} from Eq. (52) QLBS Q-Learner in the Black-Scholes-Merton article\n",
    "\n",
    "        Arguments:\n",
    "        t - time index, a scalar, an index into time axis of delta_S_hat\n",
    "        Pi_hat - pandas.DataFrame of dimension N_MC x T of portfolio values\n",
    "        Return:\n",
    "        B_vec - np.array() of dimension num_basis x 1\n",
    "        \"\"\"\n",
    "        tmp = Pi_hat * self.delta_S_hat[:, t] + self.coef * (np.exp((self.mu - self.r) * self.dt)) * self.sVals[:, t]\n",
    "        X_mat = self.data[t, :, :]  # matrix of dimension N_MC x num_basis\n",
    "\n",
    "        B_vec = np.dot(X_mat.T, tmp)\n",
    "        return B_vec\n",
    "\n",
    "    def seed_intrinsic(self, strike=None, cp='P'):\n",
    "        \"\"\"\n",
    "        initilaize option value and intrinsic value for each node\n",
    "        \"\"\"\n",
    "        if strike is not None:\n",
    "            self.strike = strike\n",
    "\n",
    "        if cp == 'P':\n",
    "            # payoff function at maturity T: max(K - S(T),0) for all paths\n",
    "            self.optionVals = np.maximum(self.strike - self.sVals[:, -1], 0).copy()\n",
    "            # payoff function for all paths, at all time slices\n",
    "            self.intrinsicVals = np.maximum(self.strike - self.sVals, 0).copy()\n",
    "        elif cp == 'C':\n",
    "            # payoff function at maturity T: max(S(T) -K,0) for all paths\n",
    "            self.optionVals = np.maximum(self.sVals[:, -1] - self.strike, 0).copy()\n",
    "            # payoff function for all paths, at all time slices\n",
    "            self.intrinsicVals = np.maximum(self.sVals - self.strike, 0).copy()\n",
    "        else:\n",
    "            raise Exception('Invalid parameter: %s'% cp)\n",
    "\n",
    "        self.bVals[:, -1] = self.intrinsicVals[:, -1]\n",
    "\n",
    "    def roll_backward(self):\n",
    "        \"\"\"\n",
    "        Roll the price and optimal hedge back in time starting from maturity\n",
    "        \"\"\"\n",
    "\n",
    "        for t in range(self.numSteps - 1, -1, -1):\n",
    "\n",
    "            # determine the expected portfolio value at the next time node\n",
    "            piNext = self.bVals[:, t+1] + self.opt_hedge[:, t+1] * self.sVals[:, t+1]\n",
    "            pi_hat = piNext - np.mean(piNext)\n",
    "\n",
    "            A_mat = self.function_A_vec(t)\n",
    "            B_vec = self.function_B_vec(t, pi_hat)\n",
    "            phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "            self.opt_hedge[:, t] = np.dot(self.data[t, :, :], phi)\n",
    "\n",
    "            ### START CODE HERE ### (≈ 1-2 lines of code)\n",
    "            # implement code to update self.bVals\n",
    "            # self.bVals[:,t] = your code goes here ....\n",
    "            self.bVals[:,t] = np.exp(-self.r * self.dt) * (self.bVals[:, t+1] + (self.opt_hedge[:, t+1] - self.opt_hedge[:, t]) * self.sVals[:, t+1])\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "        # calculate the initial portfolio value\n",
    "        initPortfolioVal = self.bVals[:, 0] + self.opt_hedge[:, 0] * self.sVals[:, 0]\n",
    "\n",
    "        # use only the second half of the paths generated with paths starting from S0\n",
    "        optionVal = np.mean(initPortfolioVal)\n",
    "        optionValVar = np.std(initPortfolioVal)\n",
    "        delta = np.mean(self.opt_hedge[:, 0])\n",
    "\n",
    "        return optionVal, delta, optionValVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.sVals [[ 100.           99.82991641  100.65186618 ...,   98.03413511   99.178315\n",
      "   101.86982056]\n",
      " [ 100.           98.10787183   97.51502931 ...,  105.16939378\n",
      "   104.31494925  103.68082198]\n",
      " [ 100.           98.92130232   98.98572082 ...,   81.39681658\n",
      "    81.58982518   80.71544572]\n",
      " ..., \n",
      " [ 100.           99.23045184   99.4426952  ...,   88.85403821\n",
      "    87.88846404   87.70763334]\n",
      " [ 100.           99.99848969   99.99870173 ...,   86.99813336\n",
      "    86.70728062   88.73760628]\n",
      " [ 100.          100.61884961  100.44923904 ...,  100.13329398\n",
      "   100.18815021  101.76599232]]\n",
      "X.shape =  (100, 253)\n",
      "X_min, X_max =  4.0538218437 5.12168012686\n",
      "num_basis =  12\n",
      "dim self.data =  (253, 100, 12)\n",
      "\n",
      "Time Cost of basis expansion: 4.142246246337891 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'$\\\\Pi_0$')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "strike_k = 95\n",
    "test_vol = 0.2\n",
    "test_mu = 0.03\n",
    "dt = 0.01\n",
    "rfr = 0.05\n",
    "num_paths = 100\n",
    "num_periods = 252\n",
    "\n",
    "hMC = DiscreteBlackScholes(100, strike_k, test_vol, 1., rfr, test_mu, num_periods, num_paths)\n",
    "hMC.gen_paths()\n",
    "\n",
    "t = hMC.numSteps - 1\n",
    "piNext = hMC.bVals[:, t+1] + 0.1 * hMC.sVals[:, t+1]\n",
    "pi_hat = piNext - np.mean(piNext)\n",
    "\n",
    "A_mat = hMC.function_A_vec(t)\n",
    "B_vec = hMC.function_B_vec(t, pi_hat)\n",
    "phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "opt_hedge = np.dot(hMC.data[t, :, :], phi)\n",
    "\n",
    "# plot the results\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "ax1.scatter(hMC.sVals[:,t], pi_hat)\n",
    "ax1.set_title(r'Expected $\\Pi_0$ vs. $S_t$')\n",
    "ax1.set_xlabel(r'$S_t$')\n",
    "ax1.set_ylabel(r'$\\Pi_0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grading' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-80648628c03f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpart1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msubmissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpart1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOURSERA_EMAIL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOURSERA_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubmissions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpi_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m### GRADED PART (DO NOT EDIT) ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grading' is not defined"
     ]
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "\n",
    "part_1 = list(pi_hat)\n",
    "try:\n",
    "    part1 = \" \".join(map(repr, part_1))\n",
    "except TypeError:\n",
    "    part1 = repr(part_1)\n",
    "submissions[all_parts[0]]=part1\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:1],all_parts,submissions)\n",
    "pi_hat\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 7)\n",
      "X_min, X_max =  2.96880459823 6.37164911461\n",
      "num_basis =  12\n",
      "dim self.data =  (7, 50000, 12)\n",
      "\n",
      "Time Cost of basis expansion: 113.05380511283875 seconds\n",
      "Option value =  13.1083499076\n",
      "Option value variance =  5.17079676287\n",
      "Option delta =  -0.356133722933\n",
      "BS value 13.1458939003\n"
     ]
    }
   ],
   "source": [
    "# input parameters\n",
    "s0 = 100.0\n",
    "strike = 100.0\n",
    "r = 0.05\n",
    "mu = 0.07 # 0.05\n",
    "vol = 0.4\n",
    "T = 1.0\n",
    "\n",
    "# Simulation Parameters\n",
    "numPaths = 50000  # number of Monte Carlo trials\n",
    "numSteps = 6\n",
    "\n",
    "# create the class object\n",
    "hMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\n",
    "\n",
    "# calculation\n",
    "hMC.gen_paths()\n",
    "hMC.seed_intrinsic()\n",
    "option_val, delta, option_val_variance = hMC.roll_backward()\n",
    "bs_call_value = bs_put(0, s0, K=strike, r=r, sigma=vol, T=T)\n",
    "print('Option value = ', option_val)\n",
    "print('Option value variance = ', option_val_variance)\n",
    "print('Option delta = ', delta)  \n",
    "print('BS value', bs_call_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission successful, please check on the coursera grader page for the status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.10834990762385"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part2 = str(option_val)\n",
    "submissions[all_parts[1]]=part2\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:2],all_parts,submissions)\n",
    "option_val\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 7)\n",
      "X_min, X_max =  2.96880459823 6.37164911461\n",
      "num_basis =  12\n",
      "dim self.data =  (7, 50000, 12)\n",
      "\n",
      "Time Cost of basis expansion: 91.0510139465332 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  6.70326307,   8.59543726,  10.74614496,  13.1458939 ,\n",
       "        15.78197485,  18.63949388])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strikes = np.linspace(85, 110, 6)\n",
    "results = [None] * len(strikes)\n",
    "bs_prices = np.zeros(len(strikes))\n",
    "bs_deltas = np.zeros(len(strikes))\n",
    "numPaths = 50000\n",
    "hMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\n",
    "hMC.gen_paths()\n",
    "for ix, k_strike in enumerate(strikes):\n",
    "    hMC.seed_intrinsic(k_strike)\n",
    "    results[ix] = hMC.roll_backward()\n",
    "    bs_prices[ix] = bs_put(0, s0, K=k_strike, r=r, sigma=vol, T=T)\n",
    "    bs_deltas[ix] = norm.cdf(d1(s0, K=k_strike, r=r, sigma=vol, T=T)) - 1\n",
    "bs_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc_prices = np.array([x[0] for x in results])\n",
    "mc_deltas = np.array([x[1] for x in results])\n",
    "price_variances = np.array([x[-1] for x in results])\n",
    "prices_diff = mc_prices - bs_prices\n",
    "deltas_diff = mc_deltas - bs_deltas\n",
    "# price_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission successful, please check on the coursera grader page for the status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03641511, -0.04034139, -0.03996597, -0.03754399, -0.03240009,\n",
       "       -0.02997062])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "\n",
    "part_3 = list(prices_diff)\n",
    "try:\n",
    "    part3 = \" \".join(map(repr, part_3))\n",
    "except TypeError:\n",
    "    part3 = repr(part_3)\n",
    "submissions[all_parts[2]]=part3\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:3],all_parts,submissions)\n",
    "prices_diff\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission successful, please check on the coursera grader page for the status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01279798,  0.01416019,  0.01532701,  0.01645681,  0.01715345,\n",
       "        0.01780652])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "part_4 = list(deltas_diff)\n",
    "try:\n",
    "    part4 = \" \".join(map(repr, part_4))\n",
    "except TypeError:\n",
    "    part4= repr(part_4)\n",
    "submissions[all_parts[3]]=part4\n",
    "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:4],all_parts,submissions)\n",
    "deltas_diff\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "reinforcement-learning-in-finance"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
